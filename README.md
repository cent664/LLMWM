# Watermarking Language Models through Language Models
---
This repository presents our approach to watermarking language model outputs using dynamically constructed system instructions generated by a Prompting Language Model (PLM). The figure below illustrates our full pipeline, highlighting the interaction between user requests, system instructions, the Marking LM (MLM), and the Detecting LM (DLM).

**Overview of the proposed scheme:**
---
![overview](https://github.com/user-attachments/assets/6f26dbfa-5cbe-412d-9953-5d1076e4bba8)


**ðŸ’¬ Fixed Prompt for the Prompting Language Model:**
---
The fixed prompt used to guide the PLM in generating system instructions is shown below. This template ensures consistent instruction generation while allowing for diverse lexical, semantic, or structural watermarking strategies.
![fixed_p](https://github.com/user-attachments/assets/31aecde7-c20e-44fa-8fa0-d775640500fb)

**ðŸ“Š Results Snapshot:**
---
The following screenshot summarizes our main quantitative findings, including detection accuracy under fine-tuning and distillation. Our method achieves high robustness even under model transformations, demonstrating the reliability and adaptability of the watermark signal.
![Capture](https://github.com/user-attachments/assets/8b1a7855-e797-427f-8cdb-3370eb6b3e9f)
