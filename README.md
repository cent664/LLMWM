# Watermarking Language Models through Language Models
---

**ğŸ” Project Overview**
This repository presents our approach to watermarking language model outputs using dynamically constructed system instructions generated by the Prompting LM. The figure below illustrates our full pipeline, highlighting the interaction between user requests, system instructions, the Marking LM, and the Detecting LM.

**Overview of the proposed scheme:**
![overview](https://github.com/user-attachments/assets/6f26dbfa-5cbe-412d-9953-5d1076e4bba8)


**ğŸ’¬ Fixed Prompt for the Prompting Language Model:**
The fixed prompt used to guide the Prompting LM in generating system instructions is shown below. This template ensures consistent instruction generation while allowing for diverse lexical, semantic, or structural watermarking strategies.
![fixed_p](https://github.com/user-attachments/assets/31aecde7-c20e-44fa-8fa0-d775640500fb)

**ğŸ“Š Results Snapshot:**
The following screenshot summarizes our main quantitative findings, including detection accuracy under fine-tuning and distillation. Our method achieves high robustness even under model transformations, demonstrating the reliability and adaptability of the watermark signal.
![Capture](https://github.com/user-attachments/assets/8b1a7855-e797-427f-8cdb-3370eb6b3e9f)

---
**ğŸ“š Citation:**
@misc{your2024watermarking,
  title={Robust Watermarking via Prompt-Based Instruction Injection in Language Models},
  author={Your Name and Collaborator Name(s)},
  howpublished={arXiv preprint arXiv:XXXX.XXXXX},
  year={2024},
  note={Under review}
}

ğŸ“Œ This citation will be updated once the paper is officially published.
