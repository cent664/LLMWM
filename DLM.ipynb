{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263dc552-46ec-44a1-9aa8-81b66833c040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !jupyter nbconvert DLM.ipynb --to python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf63033-62e5-426b-91ea-287fc1389e86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Imports**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb5fd0-db81-4692-b469-bc46c19f495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52bf6b-b673-477d-aea3-6431857df9df",
   "metadata": {},
   "source": [
    "**Hparams**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f70489-b218-49f5-806d-2e647af69185",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "MAX_LENGTH = 512 # C_H\n",
    "MODEL_NAME = \"roberta-base\" # C_H\n",
    "num_unfrozen_layers = 1\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "PROMPING_MODEL_KEY = \"mistral_7b_v03_instruct\"\n",
    "MARKING_MODEL_KEY = \"mistral_7b_v03_instruct\"\n",
    "USING_MAX_DATASET = True # C_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b30959-89c9-4144-ae60-2c208201947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fine-tuned\n",
    "# MARKING_MODEL_KEY = f\"fine_tuned_{MARKING_MODEL_KEY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84022710-7057-4f78-a957-715bc7e1e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = f\"{MAX_LENGTH}_{MODEL_NAME}\" # C_H\n",
    "\n",
    "if USING_MAX_DATASET:\n",
    "    input_directory = f\"Datasets/10k/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}_data\"\n",
    "    output_directory = f\"DLM/10k/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}/{experiment}\"\n",
    "else:\n",
    "    input_directory = f\"Datasets/1k/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}_data\"\n",
    "    output_directory = f\"DLM/1k/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}/{experiment}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa31fb-762f-4928-bf1a-7e8a562b69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Distillation\n",
    "# TEACHER_MODEL_KEY = \"llama3_8b_instruct\"\n",
    "\n",
    "# if USING_MAX_DATASET:\n",
    "#     input_directory = f\"Datasets/10k/PLM_{PROMPING_MODEL_KEY}/distilled_{TEACHER_MODEL_KEY}_to_{MARKING_MODEL_KEY}_data\"\n",
    "#     output_directory = f\"DLM/10k/PLM_{PROMPING_MODEL_KEY}/distilled_{TEACHER_MODEL_KEY}_to_{MARKING_MODEL_KEY}/{experiment}\"\n",
    "# else:\n",
    "#     input_directory = f\"Datasets/1k/PLM_{PROMPING_MODEL_KEY}/distilled_{TEACHER_MODEL_KEY}_to_{MARKING_MODEL_KEY}_data\"\n",
    "#     output_directory = f\"DLM/1k/PLM_{PROMPING_MODEL_KEY}/distilled_{TEACHER_MODEL_KEY}_to_{MARKING_MODEL_KEY}/{experiment}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6fc6d-b455-43fa-8618-7e8ea1246908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model names\n",
    "MODEL_NAMES = {\n",
    "    # Working PLM models\n",
    "    \"mistral_7b_v03_instruct\": \"mistralai/Mistral-7B-Instruct-v0.3\",  #✅ Works\n",
    "    \n",
    "    # MLM models (teacher)\n",
    "    \"deepseek_llm_chat\": \"deepseek-ai/deepseek-llm-7b-chat\",  # ✅ Works\n",
    "    \"qwen2.5_7b_instruct\": \"Qwen/Qwen2.5-7B-Instruct\",  # ✅ Works\n",
    "    \"llama3_8b_instruct\": \"meta-llama/Meta-Llama-3-8B-Instruct\",  # ✅ Works\n",
    "    \"gemma_7b_it\": \"google/gemma-7b-it\",  # ✅ Works\n",
    "    \"ministral_8b_instruct\": \"mistralai/Ministral-8B-Instruct-2410\",  #✅ Works\n",
    "    \"glm_4_9b_chat\": \"THUDM/glm-4-9b-chat\",  # ✅ Works\n",
    "    \"internlm2.5_7b_chat\": \"internlm/internlm2-chat-7b\",  # ✅ Works\n",
    "\n",
    "    \"gpt4o: manual\"\n",
    "    \n",
    "    # Student models\n",
    "    \"mistral_7b_v02_instruct\": \"mistralai/Mistral-7B-Instruct-v0.2\",  # ✅ Works\n",
    "    \"qwen1.5_1.8b_instruct\": \"Qwen/Qwen1.5-1.8B-Chat\",  # ✅ Works\n",
    "    \"tinyllama_1.1b_chat\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",  # ✅ Works\n",
    "    \"gemma_1.1_2b_it\": \"google/gemma-1.1-2b-it\",  # ✅ Works\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8543c8a9-2387-436f-8657-c51a57f4bedc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Special case for GPT-4o**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e922a-3286-4c8a-a3c3-768dd04ebd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MARKING_MODEL_KEY == \"gpt4o\":\n",
    "    input_directory = \"Datasets/GPT-4o\"\n",
    "    output_directory = f\"DLM/300/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}/{experiment}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc552f1-e741-46ea-aedb-127de75514e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Special case for testing**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35fddc-6cd4-45ac-887d-9062ffc6fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ablation = False\n",
    "experiment = 'all'\n",
    "\n",
    "test_attack = False\n",
    "ATTACK_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac769a9-adcf-4bf0-ba42-7ed9c0dc1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_ablation:\n",
    "    input_directory = f\"ablation/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}_data/{experiment}\"\n",
    "    output_directory = f\"ablation/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}/{experiment}\"\n",
    "elif test_attack:\n",
    "    input_directory = f\"attack/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}_data/attack_{ATTACK_INDEX}\"\n",
    "    output_directory = f\"attack/PLM_{PROMPING_MODEL_KEY}/{MARKING_MODEL_KEY}/attack_{ATTACK_INDEX}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66bd8c-eda2-41c0-8538-df507e51b97a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Dataset**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6464c7e-1f7d-4fdd-9498-b14b552e835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec3420-25fb-40cb-b3ab-fe8e6b29b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process dataset\n",
    "all_files = glob.glob(os.path.join(input_directory, \"*.csv\"))\n",
    "dfs = [pd.read_csv(f) for f in all_files]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "texts = df['NON-WATERMARKED RESPONSE'].tolist() + df['WATERMARKED RESPONSE'].tolist()\n",
    "labels = [[0, 1]] * len(df) + [[1, 0]] * len(df)\n",
    "\n",
    "# Tokenize\n",
    "encodings = tokenizer(texts, padding='max_length', truncation=True, max_length=MAX_LENGTH, return_tensors='tf')\n",
    "input_ids = encodings['input_ids']\n",
    "attention_mask = encodings['attention_mask']\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "# Shuffle the dataset (inputs and labels in sync)\n",
    "dataset_size = input_ids.shape[0]\n",
    "indices = tf.random.shuffle(tf.range(dataset_size))\n",
    "input_ids = tf.gather(input_ids, indices)\n",
    "attention_mask = tf.gather(attention_mask, indices)\n",
    "labels = tf.gather(labels, indices)\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_size = int(0.8 * dataset_size)\n",
    "train_data = (input_ids[:train_size], attention_mask[:train_size], labels[:train_size])\n",
    "val_data = (input_ids[train_size:], attention_mask[train_size:], labels[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d544d-6033-4fd9-8d57-33ee05125c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "def create_dataset(inputs, masks, labels):\n",
    "    return tf.data.Dataset.from_tensor_slices(((inputs, masks), labels)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "train_dataset = create_dataset(*train_data)\n",
    "val_dataset = create_dataset(*val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bac396-0189-480e-8bed-783d9b460936",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**MultiGPU strategy**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06e7a5-d717-45d1-8bbd-0768200120b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb88e85-43e3-4774-95e1-699acb0f76b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823aeceb-97d6-46de-ba81-747b419645b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_detecting_llm_tf(MODEL_NAME, MAX_LENGTH=512):\n",
    "    # Load model\n",
    "    base_model = TFAutoModel.from_pretrained(MODEL_NAME)\n",
    "    encoder_layers = base_model.roberta.encoder.layer\n",
    "    if encoder_layers is not None:\n",
    "        for i, layer in enumerate(encoder_layers):\n",
    "            layer.trainable = i >= len(encoder_layers) - num_unfrozen_layers\n",
    "    else:\n",
    "        print(f\"Warning: Unknown model structure for '{MODEL_NAME}', freezing all layers.\")\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Define inputs\n",
    "    input_ids_layer = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask_layer = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "    # CLS output → Dense head\n",
    "    outputs = base_model(input_ids_layer, attention_mask=attention_mask_layer)[0][:, 0, :]\n",
    "    logits = tf.keras.layers.Dense(2, activation='sigmoid')(outputs)\n",
    "\n",
    "    # Final model\n",
    "    model = tf.keras.Model(inputs=[input_ids_layer, attention_mask_layer], outputs=logits)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870699c-d5c4-4253-b8c2-2a648ed9da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_detecting_llm_tf(\"roberta-base\", MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6506b-3cd5-4550-b743-08b14849d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07250e1c-3fd9-4e15-a22f-d04068f8f970",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Training**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64af60e-052e-4349-9373-575705037a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerboseCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs.get(\"val_accuracy\")\n",
    "        if val_acc is not None and val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            self.best_epoch = epoch\n",
    "            print(f\"✅ New best val_accuracy: {val_acc:.4f} at epoch {epoch + 1}\")\n",
    "        else:\n",
    "            print(f\"val_accuracy did not improve from {self.best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18448605-61cf-4c2c-b21a-2ba8e25456d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(output_directory, \"best_DLM_weights.h5\")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy',\n",
    "                                       save_best_only=True, save_weights_only=True),\n",
    "    VerboseCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8fa47-56ca-4a1b-a725-fb39937e5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fd7cb-8393-4201-aa6a-0c79e5019b7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Plotting**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226d2cf-bfdb-4160-b93c-605ad9939c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and validation accuracy\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs_range = range(1, len(train_acc) + 1)\n",
    "\n",
    "# Find best validation accuracy and corresponding epoch\n",
    "best_epoch = int(np.argmax(val_acc))\n",
    "best_val_acc = val_acc[best_epoch]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_range, train_acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label=f'Val Accuracy (best: {best_val_acc:.4f})')\n",
    "plt.scatter(best_epoch + 1, best_val_acc, color='red', zorder=5)  # +1 to match epoch number (1-indexed)\n",
    "\n",
    "# Labels and styling\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_directory, \"accuracy_plot.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cent",
   "language": "python",
   "name": "temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
